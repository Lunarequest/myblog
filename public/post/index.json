[{"ref":"https://nullrequest.com/post/self_hosting_part2/","title":"Self hosting part 2","section":"post","date":"2020.08.29","body":"Background This is a continuation of the previous post. This will be part 2 of 3 hopefully if I can get my custom tools working. Alot has changed since last post. If you are reading this on the netlify subdomain please head over to http://nullrequest.com and continue reading. The linked website is curently running on my own hardware!!!!! Before I continue big thanks to sesa. She really helped my with my nginx configs.\nThe three stages????? Yeah my 3 stages plan went sort of bupkis when I relasied I could only test once I deployed everything but that doesn\u0026rsquo;t mean I haven\u0026rsquo;t worked on the custom tooling at all. Infact if you check out my github you\u0026rsquo;ll find the cloudflare-DDNS repo. This is hopfully the start of a script that should allow use to update the ip without ever having to touch the dashboard on cloudflare. If you have a pfsense box pfsense can actually handle it for you. I may get one in the future but until then its no dice. I\u0026rsquo;ll take about how I deployed everything in this post.\nNginx Nginx is sort of like the holy grail for us right now. If we had embarked on this project before 2004 we would have had to use Apache. While there is nothing inherntly wrong with apache its very very difficult to setup. So then smooth sailing? well no. Nginx on arch is the bare minimum ngnix distribution. It makes things interesting if you like a challange. If not use ubuntu and yeah alot of steps can be skipped. I can\u0026rsquo;t tell you what steps but go through you should be able to figure it out. On arch linux there are 2 versions of nginx. I recomand the mainline version as it will have the latest features. The bellow command should install nginx mainline.\n# pacman -S nginx-mainline Before we start we need to \u0026ldquo;minify\u0026rdquo; all html and css so ngnix can serve the files. Hugo saves us alot of time as it has a simple command to create all the html in a minified form. This means there are no spaces in the html.\n$ hugo --gc --minify -b url Replace url with you url. After the command finishes it will create a folder called public. It will have all the html and css needed to deploy the website. I copied all the files to /var/www/nameofwebsite and changed the ownership of the files using chown to the http user.\nconfigs ngnix on arch needs some modifications to a few files to make it simpler to deploy websites and services. First we need to edit ngnix.conf on other linux distros you might make a config at sites-avalible and symlink it to sites-enabled however arch actually doesn\u0026rsquo;t load the server blocks in sites-enabled. However making arch load it is pretty simple. Open /etc/nginx/nginx.conf in a text editor of your choice and add this too the http block\ninclude sites-enabled/*; Next up we can create sites-enabled and sites-avalible. You can do this however you want but I am partial to mkdir.\n# mkdir /etc/nginx/sites-avalible # mkdir /etc/nginx/sites-enabled Now we can make our first \u0026ldquo;server block\u0026rdquo;, A server block esstentially means based on the url or ip address used we can decied what to do with the request. This means you can run multiple websites of the same server with little too no conflicts. To start lets make a site in sites-avalible.\n# touch /etc/nginx/sites-avalible/myblog Before we continue with setting up nginx lets setup cloudflare and get a origin cert. First lets head to https://www.canyouseeme.org/. This service should get you your public ip. This will change over time. You may need to update your dns records to reflect your new ip when your ip changes. Get your public IP adress. You need to setup cloudflare with your domain and change TLS to full. Next get a origin cert from cloudflare. You will get a certificate and a key. copy the certifcate text to  /etc/ssl/youdoaminahere.pem and the key to /etc/ssl/yourdomainhere.key\nNow we need to open the file in a texteditor. I used vim but you can use what texteditor you are comfortable with. Now we can configure everything in ngnix.\nserver { listen 443 ssl; server_name yourdomainhere; ssl_certificate /etc/ssl/youdomainhere.pem; ssl_certificate_key /etc/ssl/yourdomainhere.key; access_log /var/log/nginx/nginx.vhost.access.log; error_log /var/log/nginx/nginx.vhost.error.log; root /var/www/yourdomainhere; index index.html index.htm; location / { try_files $uri $uri/ =404; } error_page 404 404.html; } I know this alot to process but I\u0026rsquo;ll break everything down line by line. server { the first line tell ngnix whats follows is a server block. listen 443 ssl; This tells nginx to listen on port 443 and use ssl. The next line tells nginx that this block is realted to your domain and not use it for other ones. The next 2 lines are for https. Nginx needs to know where to get the cert and key.\naccess_log /var/log/nginx/nginx.vhost.access.log; error_log /var/log/nginx/nginx.vhost.error.log; These lines bassically tell nginx where to wrtie logs too. These can be pretty interesting to go through. REMEMBER LOGS ARE YOUR BEST FREIND WHEN DEBUGGING. root /var/www/yourdomainhere; this line bassically tells nginx which directory the files are located saving you the hassel of using absolute paths. index index.html index.htm; If you have been paying attention you should be able to guess that this line tells nginx to server index.html or index.htm based on what exists when someone acess the raw url.\nlocation / { try_files $uri $uri/ =404; } This section is a bit simple logic that says in simple terms look for a file or path that the url has. Serve the file if you find it. If you don\u0026rsquo;t return a 404 error code. error_page 404 404.html; The last line tells nginx that if you have a 404 serve the 404.html document to the user.\nAfter this you can run the following command to check if there are errors in your code.\n# nginx -t With this we can finish our configs and start the nginx service.\n$ systemctl start nginx Port forwading This part is basically the last step to deploying our website. This step will change for your router you should be able to setup everything pretty simply. you need to forward 443 on LAN to WAN and with that you should have a working website. You can check if everything works using https://www.canyouseeme.org/. You can set the port to 443.\nThe next post will be about my work with custom tools that I will be making. If you are still on the old url comments will not work. I will be keeping the website up for a month or two before taking the old url down.\n— This is nullrquest signing off\n"},{"ref":"https://nullrequest.com/post/self_hosting/","title":"Self hosting","section":"post","date":"2020.08.20","body":"Background Recently I found out that my freind self hosted her website. I was actually pretty suprised this was possible. After finding out this was possible I began working on porting my blog to be run off netfliy and on my own servers. This is going to be my first long term porject and series. I will be posting around once a month with updates and changes I will be implementing.\nThe base machine I currently will be hosting my webiste off a HP Compaq 8000 Elite. This isn\u0026rsquo;t ideal however as time passes I will be replacing this with more powerfull hardware. I plan to use a headless arch linux install as the os running on it. I am sure alot of you will be getting ready to hit my comment section going \u0026ldquo;null arch linux is a rolling distro, its not stable\u0026rdquo; and my response would be \u0026ldquo;well yes but no\u0026rdquo;. Why the weird yes but no. Well arch linux lacks a stable relase it is actually very stable.\nWhat many people tend to forget is that arch linux has a testing branch. It would be sucide to use the testing branch on a production server. why? well testing has everything out of the box no fixes, no patches to fix things on arch. The regular repos are actually very stable and may require people to manually fix issues during updates. Which is why exist.\nThe stages I\u0026rsquo;ve broken this move down to three stages.\n rework custom tooling deploy  Stage 1 is what I am working on right now. currently alot of the website relies on netlify to work. like in the contact form. I am working on steadly removing netlify from the equation. With this post you will see the biggest change so far. The contact form will no longer use netify. Over time this will extend to the rest of the webiste. Stage 2 will invlove writing scripts to automate everything and stage 3 is testing everything while deployinig it.\nI hope you enjoyed this shorter then normal post. I will be back in a few weeks with another post hopefully entering stage 2.\n— This is nullrquest signing off\n"},{"ref":"https://nullrequest.com/post/arch_automation/","title":"Arch install automation","section":"post","date":"2020.08.06","body":"background I have a OEM desktop that I use as a headless(without a display) server. I found that I nuke this server very often when I mess something up and have to reinstall. With my recent move switching to Arch as my primary operating system. Reinstalling became a hassel. This post will take a diffrent approch. Rather then give instructions on how to make/build everything. I will talk about what I did and why I did that.\nThe plan First I need to make a custom iso. This iso had to boot regularly some how tell my laptop its ip and finally get sshed into by ansible which will allow ansible to install arch for me. I broke the problem down into stages stage 1. get the ip stage 2. auth in ssh without password stage 3. install arch\nStage 1 Stage 1 was the simplest part of the project. I started with finding out how I could get my IP. For this section I exmployed Python. I used python due to my fimilarity with it. To get the IP adress I used socket. This is the function I used to get my IP.\ndef get_ip(): s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) s.connect((\u0026#34;8.8.8.8\u0026#34;, 80)) ip = s.getsockname()[0] s.close() return ip Its a nifty little piece of code that pings googles DNS server and then gets the current ip from the socket and closes the socket. The next part stumped me for a while. How would I send the ip to my laptop. After about 5 minutes of thinking I though maybe I could run a Django webserver. After 5 more minutes of thinking I came to the conclusion that while the idea was right using a webserver would be good django was overkill. Enter our next contender flask. Flask is the arch of the python web dev world. While Django neatly handles 99% of the work flask is the opposite. You need to configure and handle everything(well almost everything).\nI Would like to show my flask code but its nothing special. It recives the the request (a get in this case) and prints the ip which is sent as a parameter of the get request. To send the get request I used the requests python module. the function for this was suprisngly simple to use.\ndef send_ip(ip): URL = \u0026#34;http://127.0.0.1:5000\u0026#34; PARAMS = {\u0026#34;ip\u0026#34;: ip} r = requests.get(url=URL, data=PARAMS) print(r) print(r.text) currently the url is set to localhost but you can change it to the ip of your system. This is where my first road block was hit. I orginally planed to use systemd to load up and run the program for me. Sadly the systems ip isn\u0026rsquo;t set until the DHCP negtations are run made by dhcpcd. So I moved to plan b using the zshrc. At this point I spent 2 days lerning, making and testing a custom arch iso. At this point I realised that I could tackel stage 2 with the iso. The only side effect present is when you ssh you will not see a propmt on the iso.\nStage 2 A password isn\u0026rsquo;t the only way to login to a remote host using ssh. The alterntive more secure method is a SSH key. A key pair(one private and one public) can be made fairly quickly. I recomand follow the guide by github on how to set it up. So I add a section in the iso to copy my key into the iso. allowing me to login and execute commands as root without ever inputing the password.\nStage 3 This was what held me back for a short while(okay it wasn\u0026rsquo;t a short while it was a month). At one point I thought of using Chef instead of ansible. While I did start porting to chef. It quickly ended becuase chef just doesn\u0026rsquo;t have modules like asibles parted module. The install is pretty standard except instead of using arch-chroot /mnt you have to run command outside and when it needs to be run inside a chroot you use arch-chroot /mnt command. There was 2 problems that really stumpped me when I ran into them. The first one was the grub install. I used grub over systemd because the server only had bios support.\nI discorved you dont give grub-install a partion but rather the entier disk like grub-install /dev/sda. After this the install was pretty smooth sailing. Until I hit the user creation section. Currently I haven\u0026rsquo;t figured out how to fix the issue but the one solution I am trying to get working is chpasswd. If someone figures out how it works please do hit me up. I really would like to solve it. I will be uploading everything to my github so anyone can use it. One last thing. If you want to install arch do it yourself. Do your research and it will pay off. Installing arch teachs you alot about how linux works. Also don\u0026rsquo;t use arch as your first Linux distro use linux mint or pop os\n— This is nullrequest signing off\n"},{"ref":"https://nullrequest.com/post/ultimate_arch_setup/","title":"Ultimate arch linux setup","section":"post","date":"2020.07.28","body":"Background Recently after distro-hopping I came back to Arch linux. It was perfect for me and I really can\u0026rsquo;t move to another distro without missing the AUR. After installing Arch I went through a few extra steps to add some features like secure boot(I know its not needed) and plymouth to add m to my setup. I am assuming you have used linux this does not and will not replace the arch wiki.\nThe arch install. This is the most difficult part of arch.I will not be making a guide for it as Arch linux changes very often and the best source is the Arch wiki. I know its scary but put in the hard work and you will be rewarded with a arch install.\nSwapFiles swapfiles are like swap partions but rather then use a partion it uses a file. Usually this is /swapfile. To start with you will need to make a file. If you use btrfs you will need to add set some permsions.\n$ sudo dd if=/dev/zero of=/swapfile bs=1M count=512 status=progress Change count to the size of ram you have if you want to hibernate. Next up we need to remove the read permissons on the file. Its supersingly easy to change this. sudo chmod 600 /swapfile will allow remove the read/write permssions. Next we need to format the file to make it a swap device. This step is very simple.\n$ sudo mkswap /swapfile Next you should activate the swap device like this sudo swapon /swapfile. Finally you should edit the fstab file to ensure its actived on boot. You can edit the /etc/fstab file with you prefered text editor. Add the following line at the end and when you reboot your system should activate the swap device.\n/swapfile none swap defaults 0 0 Secure boot I am using custom keys and have wiped the microsoft keys of my system for better security. If you want to keep these keys you will need to use preboot/shim. Look into the arch wiki on how to use them. To start off we need to install efitools\n$ sudo pacman -S efitools I accutuly did everything here in a folder I created. The path is /etc/secure-boot/. I recomand doing the same. First we create a GUID\n$ uuidgen --random \u0026gt; GUID.txt next up we create a Platform key\n$ openssl req -newkey rsa:4096 -nodes -keyout PK.key -new -x509 -sha256 -days 3650 -subj \u0026#34;/CN=my Platform Key/\u0026#34; -out PK.crt $ openssl x509 -outform DER -in PK.crt -out PK.cer $ cert-to-efi-sig-list -g \u0026#34;$(\u0026lt; GUID.txt)\u0026#34; PK.crt PK.esl $ sign-efi-sig-list -g \u0026#34;$(\u0026lt; GUID.txt)\u0026#34; -k PK.key -c PK.crt PK PK.esl PK.auth $ sign-efi-sig-list -g \u0026#34;$(\u0026lt; GUID.txt)\u0026#34; -c PK.crt -k PK.key PK /dev/null rm_PK.auth # this is to allow the key to be removed in the future Next the Key exchange key or KEK\n$ openssl req -newkey rsa:4096 -nodes -keyout KEK.key -new -x509 -sha256 -days 3650 -subj \u0026#34;/CN=my Key Exchange Key/\u0026#34; -out KEK.crt $ openssl x509 -outform DER -in KEK.crt -out KEK.cer $ cert-to-efi-sig-list -g \u0026#34;$(\u0026lt; GUID.txt)\u0026#34; KEK.crt KEK.esl $ sign-efi-sig-list -g \u0026#34;$(\u0026lt; GUID.txt)\u0026#34; -k PK.key -c PK.crt KEK KEK.esl KEK.auth Finally the Signature Database key.\n$ openssl req -newkey rsa:4096 -nodes -keyout db.key -new -x509 -sha256 -days 3650 -subj \u0026#34;/CN=my Signature Database key/\u0026#34; -out db.crt $ openssl x509 -outform DER -in db.crt -out db.cer $ cert-to-efi-sig-list -g \u0026#34;$(\u0026lt; GUID.txt)\u0026#34; db.crt db.esl $ sign-efi-sig-list -g \u0026#34;$(\u0026lt; GUID.txt)\u0026#34; -k KEK.key -c KEK.crt db db.esl db.auth Now we need to sign the kernels and efi binaries.\n$ sudo sbsign --key db.key --cert db.crt --output /boot/vmlinuz-linux /boot/vmlinuz-linux $ sudo sbsign --key db.key --cert db.crt --output esp/EFI/BOOT/BOOTX64.EFI esp/EFI/BOOT/BOOTX64.EFI You will need to do this everytime you update the kernel or bootloader. I used a pacman hook to do this. I also moved all the keys to /etc/secure-boot\n$ sudo nano /etc/pacman.d/hooks/99-secureboot.hook My hook is the following\n[Trigger] Operation = Install Operation = Upgrade Type = Package Target = linux Target = systemd [Action] Description = Signing Kernel for SecureBoot When = PostTransaction Exec = /usr/bin/sh -c \u0026quot;/usr/bin/find /boot/ -type f \\( -name 'vmlinuz-*' -o -name 'systemd*' \\) -exec /usr/bin/sh -c 'if ! /usr/bin/sbverify --list {} 2\u0026gt;/dev/null | /usr/bin/grep -q \\\u0026quot;signature certificates\\\u0026quot;; then /usr/bin/sbsign --key /etc/secure-boot/db.key --cert /etc/secure-boot/db.crt --output {} {}; fi' \\;\u0026quot; Depends = sbsigntools Depends = findutils Depends = grep You should also copy all the keys to the /boot partion. Next you need to put your firmware into setup mode and enroll the keys. You can follow this guide on how to enroll the keys www.rodsbooks.com/efi-bootloaders/controlling-sb.html#setuputil.\nPlymouth Fist we need to install a aur helper. I prefer yay but you can use any helper or manully git clone and makepkg each package on your own.\n$ git clone https://aur.archlinux.org/yay.git These packages are a must if you want to install any aur package.\n$ sudo pacman -S fakeroot binuitls Next to build and install yay. run these commands\n$ makepkg -si After this we can install plymouth.\n$ yay plymouth You can install the git or stable version. Next you need to edit the /etc/mkinitcpio.conf.\n$ sudo nano /etc/mkinitcpio.conf you need to add the plymouth hook to the HOOKS section HOOKS=(base udev plymouth ...). You might also need to add your drivers kernel module.\nAt this point its time to get a theme for the plymouth screen. I used this theme. However you can use the one you perfer.\nYou can get a list of choices using the following command\n$ plymouth-set-default-theme -l Finally to set the theme run\n$ sudo plymouth-set-default-theme -R theme Add this to the options line in the arch.conf in the /boot partition. quiet splash loglevel=3 rd.udev.log_priority=3 vt.global_cursor_default=0 After this you can reboot the system and you should have your theme shown when you boot up.\nHibrenation Hibrenation is a usefull requirment on laptops. When a laptop enters hibernation it saves the contents of ram to the hdd/sdd saving power but speeding up boot time. On arch linux you need to add kernel hooks and parameters to tell the system on how to resume. To start off we can add the mkinitcpio hook. You should open the /etc/mkinitcpio.conf file in a text editor and updated the hooks.\nHOOKS=(base udev plymouth autodetect modconf block filesystems resume keyboard fsck) The hooks should look like this now. Next we need to add a kernel parameter so the kernel knows where to resume from. However before this we need to find the \u0026ldquo;offset\u0026rdquo; of the swapfile. To do this we can use filefrag.\nFilesystem type is: ef53 File size of /swapfile is 8388608000 (2048000 blocks of 4096 bytes) ext: logical_offset: physical_offset: length: expected: flags: 0: 0.. 6143: 321536.. 327679: 6144: 1: 6144.. 12287: 403456.. 409599: 6144: 327680: 2: 12288.. 14335: 466944.. 468991: 2048: 409600: 3: 14336.. 16383: 522240.. 524287: 2048: 468992: 4: 16384.. 47103: 559104.. 589823: 30720: 524288: 5: 47104.. 49151: 673792.. 675839: 2048: 589824: 6: 49152.. 59391: 677888.. 688127: 10240: 675840: 7: 59392.. 83967: 696320.. 720895: 24576: 688128: 8: 83968.. 86015: 735232.. 737279: 2048: 720896: You should look for the first physical_offset value. In my case it was 321536. Now we are ready to add our kernel parameters. There are 2 parameters we need to add the resume parameter and the resume_offset parameter. For the resume parametere you need to use the UUID of the partion the swapfile is on. your parameter should look like this.resume=UUID=19a7a7b7-04d9-4abc-b1bf-8d53ea7de04e resume_offset=321536\nFinal thoughts I know it was a bit long but I spent a long time fixing issues and getting things working. I really enjoy arch and I hope people find this informing and enjoy setting up arch.\n— This is nullrquest signing off\n"},{"ref":"https://nullrequest.com/post/darkweb_website/","title":"How to setup Dockerised darkweb website","section":"post","date":"2020.07.15","body":"Discalmer I am not resposbile if you break something. Please consult with your laws to see if using Tor is legal in your country. A example where it is not legal is China. In most countries it is legal but again please check you laws. This guide was written for linux but may work on MacOS but will defintely not work on windows without some tweaks.\nBackground After my dockerised IRC project I realised that I wanted to host a website on the dark web. I spent a copule of hours working on this. I hope you guys like this. This tutorial uses django for the website. Below is my file structure if you want to follow.\nproject ├── app ├── docker-compose.yml ├── Dockerfile └── tor └── Dockerfile The Website The website itself can be anything assuming you use django. If you use postgress or any thing else as the database you will need to do some extra configs. This is beyond the scope of this tutorial. The docker container hosting all of this is fairly simple. You will need to add more steps the more complex your website becomes.\nFROMpython:3.8ENV PYTHONUNBUFFERED 1ENV PYTHONDONTWRITEBYTECODE 1RUN pip install django gunicornWORKDIR/usr/src/appCOPY ./app/ ./ENTRYPOINT tail -F /dev/nullgunicorn is for a later step we can ignore it for now. To test if our website works. We can run the following.\n$ docker build . -t website $ docker rm website $ docker run -d --name website -p 8000:8000 website $ docker exec -it website python manage.py runserver 0.0.0.0:8000 These will build and launch the docker container so we can test it out. You will be able to navigate to http://localhost:8000 and see your website running. At this point you can remove the last line ie. ENTRYPOINT tail -F /dev/null can be removed.\nThe Tor Container Like the IRC we will be keeping the tor proxy in a seprate container. We will need to create a new torrc. Like before, you can run the following to get the torrc file (this is assuming you are running linux, if you are not please look into your OSs configs for tor)\n$ sudo cp /etc/tor/torrc ./configs/torrc find the following lines\n#HiddenServiceDir /var/lib/tor/hidden_service/ #HiddenServicePort 80 127.0.0.1:80 Uncomment and change the second line to appeare the same as the one bellow.\nHiddenServiceDir /var/lib/tor/hidden_service/ HiddenServicePort 80 website:8000 If you are observent you might notice that the ports are weird in the config. This is to ensure that when a person connects using the Tor browser it will automatically connect to the website(using other ports will result in you having to supply a port with the address in a webbrowser like tor)\nDocker-Compose well here we are again. The docker compose file. This is a god send for us as instead of one massive command we have a small one.\nversion: \u0026#39;3.7\u0026#39; services: web: container_name: website build: . command: gunicorn hello_django.wsgi:application --bind 0.0.0.0:8000 volumes: - ./app/:/usr/src/app/ tor: container_name: tor_host build: ./tor links: - web depends_on: - web ports: - 9001:9001 - 9030:9030 Remember I said don\u0026rsquo;t worry about gunicorn a while back. Its time to worry about it. If you have used django before you will know it always states when you use manage.py runserver do not use this in a production environment. Gunicorn is one of the many option you can use in a situation like this. There are other solutions like uwsgi but they require configs so we are just going to use gunicorn(I am lazy. Sue me if you don\u0026rsquo;t like that (this is a joke)).\nLike before you can run start the entier system with the following commands.\n$ docker-compose up -d $ docker exec -it tor_host service tor start $ docker exec -it tor_host cat /var/lib/tor/hidden_service/hostname You will get a .onion link from the last command. You will not be able to use this in a regular browser. You will need to use the Tor browser to connect to the website. With some luck you will be able to connect to the website.\nFinal Notes I encourage to look the docker docs and the docker-compose docs. Learn how it works and become more confident with using docker. I hope you find this tutorial useful or interseting. Please note just using docker doesn\u0026rsquo;t make your server safe. Please learn how to setup fire walls you can use to lock down your server.\n— This is nullrquest signing off\n"},{"ref":"https://nullrequest.com/post/darkweb_irc/","title":"How to setup a darkweb IRC","section":"post","date":"2020.07.13","body":"discalmer I am not resposbile if you break something. Please consult with your laws to see if using Tor is legal in your country. An example where it is not legal is China. In most countries it is legal but again please check you laws.\nBackground Before I get into how to set everything up. I am going to give some background on why I created this guide. Around 3 months ago a discord server I was on wanted to try and create an ultra secure Internet Relay Chat (IRC for short) server. Intially we tried to use SSL to secure the server. However, we had a few issues with the certificates which resulted in the project stalling. After some time I relalised we could use Tor to run the IRC in a more secure manner. We did deploy a Tor based solution but that led to even more problems. Mainly secuity concerns about what would happen if Tor was breached, thus began a 3 week odeasy to Dockerising the setup. Without further ado lets get into the tutorial. This tutorial assumes you use Linux, however this will work with any Opertaing system with some tweaks.\nThe IRC server I orginally intended to compile InspIRCd from source. I found out after a friend pointed out that InspIRCd has a prebuilt Docker conatiner\u0026hellip;. So yeah, I wasted a long time on the compile attempt. We are going to setup a quick test. I recomand using this setup to get an inspircd.conf setup.\n$ docker pull inspircd/inspircd-docker $ docker run --name inspircd -p 6667:6667 -v /path/to/your/config:/inspircd/conf/ inspircd/inspircd-docker If you want to use my compose file this is the file structure I used.\nproject ├── configs │ ├── inspircd.conf │ ├── modules.conf │ └── motd.txt ├── docker-compose.yml ├── setup.sh └── tor ├── configs | └──torrc └── Dockerfile So the last command will be (this is assuming that your working dir is project)\n$ docker run --name inspircd -p 6667:6667 -v ~/project/configs:/inspircd/conf/ inspircd/inspircd-docker The Tor container The tor container will, as the name implies, contain tor. This container has one job. Get the IRC online on the Darkweb. We are going to be build a custom container for this using a Dockerfile.\nFROMubuntu:focal#initRUN apt update \u0026amp;\u0026amp; apt upgrade -yRUN apt install tor -y#config torWORKDIR/home/torrcCOPY ./configs/torrc .RUN rm /etc/tor/torrcRUN cp torrc /etc/tor/ENTRYPOINT tail -F /dev/nullThe Docker image is based of Ubuntu 20.04, and uses a custom torrc file. We will need to make one of these.\n#if you do not have tor installed. install it before this step. #this assumes you are inside the tor directory in a terminal. $ sudo cp /etc/tor/torrc ./configs/torrc now open up the torrc in a a editor of your choice. you may need to change the ownership using chown find the following lines\n#HiddenServiceDir /var/lib/tor/hidden_service/ #HiddenServicePort 80 127.0.0.1:80 Uncomment and change the second line to appeare the same as the one bellow.\nHiddenServiceDir /var/lib/tor/hidden_service/ HiddenServicePort 6667 irc:6667 The more experinced among you might notice the ip for the service isn\u0026rsquo;t actually a IP but rather a hostname. this will become clearer in the next steps. finnaly build the conatiner with this command\n$ docker build tor -t tor The test run If you got this far. well congrates you have achived what took me 2 weeks of trial and error. Now we are going to test everything and hopefully have a running tor based IRC server up and running. This command launches a conatiner called irc with the base image inspircd/inspircd-docker. Tthis mount the IRC configs at /inspircd/conf/\n$ docker run --name irc -d -v ~/project/configs:/inspircd/conf/ inspircd/inspircd-docker Next run this command. This links the 2 containers with the irc conatiner having the host name irc. this is also why in the torrc we supplied a hostname(which is fixed) rather then a ip(which is not fixed).\n$ docker run -d --name tor --link=irc:irc tor the next 2 commands start the tor service and give the .onion link of the server\n$ docker exec -it tor service tor start $ docker exec -it tor cat /var/lib/tor/hidden_service/hostname the second command should spit out your .onion link. to connect to the server follow one of the options from this guide. I recomand hexchat if you are new to the IRC feild. Supply the .onoin link and in a minute you should be conneted to the server.\nDocker-compose Docker on its own is powerful and in theory you could just continue using the setup we used previously. However if you need to bring it down for maintnace bringing it back up is a PAIN and should never be used in a production evnviorment. Too solve this porblem we shall use a docker-compse.yml(you can also used a .yaml) file. this will make docker compose do the heavy lifting of mounting folders and also linking the 2 containers.\nversion: \u0026#39;3.8\u0026#39; services: irc: image: inspircd/inspircd-docker container_name: irc volumes: - type: bind source: ./configs target: /inspircd/conf/ app: build: ./tor container_name: tor ports: - 9001:9001 - 9030:9030 links: - irc depends_on: - irc volumes: {} This basically runs all the commands except starting tor and giving us the .onion link. This will speed up the enteir process. to run this use\n$ docker-compose up -d the -d flag tells it to run in detached/headless mode. finally run these 2 commands to launch the tor proxy.\n$ docker exec -it tor service tor start $ docker exec -it tor cat /var/lib/tor/hidden_service/hostname final notes I encourage to look the docker docs and the docker-compose docs. Learn how it works and become more confident with using docker. I hope you find this tutorial useful or interseting. Please note just using docker doesn\u0026rsquo;t make your server safe. Please learn how to setup fire walls you can use to lock down your server.\n— This is nullrquest signing off\n"}]